\doxysection*{● Open Interpreter（开放解释器）}



\href{https://discord.gg/6p3fD6rBVm}{\texttt{ }} \href{README_JA.md}{\texttt{ }} \href{README.md}{\texttt{ }}  ~\newline
 ~\newline
 {\bfseries{让语言模型在您的计算机上运行代码。}}~\newline
 在本地实现的开源\+Open\+AI的代码解释器。~\newline
 ~\newline
\href{https://openinterpreter.com}{\texttt{ 登记以提前获取\+Open Interpreter（开放解释器）桌面应用程序}}~\newline
 

~\newline




~\newline



\begin{DoxyCode}{0}
\DoxyCodeLine{pip install open-\/interpreter}

\end{DoxyCode}



\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter}

\end{DoxyCode}


~\newline


{\bfseries{Open Interpreter（开放解释器）}} 可以让大语言模型（\+LLMs）在本地运行代码（比如 Python、\+Java\+Script、\+Shell 等）。安装后，在终端上运行 {\ttfamily \$ interpreter} 即可通过类似 Chat\+GPT 的界面与 Open Interpreter 聊天。

本软件为计算机的通用功能提供了一个自然语言界面，比如：


\begin{DoxyItemize}
\item 创建和编辑照片、视频、\+PDF 等
\item 控制 Chrome 浏览器进行搜索
\item 绘制、清理和分析大型数据集
\item ...
\end{DoxyItemize}

{\bfseries{⚠️ 注意：在代码运行前都会要求您批准执行代码。}}

~\newline
\hypertarget{md_README_ZH_autotoc_md84}{}\doxysubsection{演示}\label{md_README_ZH_autotoc_md84}
\href{https://github.com/KillianLucas/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60}{\texttt{ https\+://github.\+com/\+Killian\+Lucas/open-\/interpreter/assets/63927363/37152071-\/680d-\/4423-\/9af3-\/64836a6f7b60}}\hypertarget{md_README_ZH_autotoc_md85}{}\doxyparagraph{Google Colab 上也提供了交互式演示：}\label{md_README_ZH_autotoc_md85}
\href{https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing}{\texttt{ }}\hypertarget{md_README_ZH_autotoc_md86}{}\doxysubsection{快速开始}\label{md_README_ZH_autotoc_md86}

\begin{DoxyCode}{0}
\DoxyCodeLine{pip install open-\/interpreter}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md87}{}\doxysubsubsection{终端}\label{md_README_ZH_autotoc_md87}
安装后，运行 {\ttfamily interpreter}：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md88}{}\doxysubsubsection{Python}\label{md_README_ZH_autotoc_md88}

\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keyword}{import} interpreter}
\DoxyCodeLine{}
\DoxyCodeLine{interpreter.chat(\textcolor{stringliteral}{"{}Plot AAPL and META's normalized stock prices"{}}) \textcolor{comment}{\# 执行单一命令}}
\DoxyCodeLine{interpreter.chat() \textcolor{comment}{\# 开始交互式聊天}}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md89}{}\doxysubsection{与 Chat\+GPT 的代码解释器比较}\label{md_README_ZH_autotoc_md89}
Open\+AI 发布的 \href{https://openai.com/blog/chatgpt-plugins\#code-interpreter}{\texttt{ Code Interpreter}} 和 GPT-\/4 提供了一个与 Chat\+GPT 完成实际任务的绝佳机会。

但是，\+Open\+AI 的服务是托管的，闭源的，并且受到严格限制：


\begin{DoxyItemize}
\item 无法访问互联网。
\item \href{https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/}{\texttt{ 预装软件包数量有限}}。
\item 允许的最大上传为 100 MB，且最大运行时间限制为 120.\+0 秒
\item 当运行环境中途结束时，之前的状态会被清除（包括任何生成的文件或链接）。
\end{DoxyItemize}

\DoxyHorRuler{0}


Open Interpreter（开放解释器）通过在本地环境中运行克服了这些限制。它可以完全访问互联网，不受运行时间或是文件大小的限制，也可以使用任何软件包或库。

它将 GPT-\/4 代码解释器的强大功能与本地开发环境的灵活性相结合。\hypertarget{md_README_ZH_autotoc_md91}{}\doxysubsection{命令}\label{md_README_ZH_autotoc_md91}
\hypertarget{md_README_ZH_autotoc_md92}{}\doxysubsubsection{交互式聊天}\label{md_README_ZH_autotoc_md92}
要在终端中开始交互式聊天，从命令行运行 {\ttfamily interpreter}：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter}

\end{DoxyCode}


或者从.\+py 文件中运行 {\ttfamily interpreter.\+chat()}：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.chat()}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md93}{}\doxysubsubsection{程序化聊天}\label{md_README_ZH_autotoc_md93}
为了更精确的控制，您可以通过 {\ttfamily .chat(message)} 直接传递消息 ：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.chat(\textcolor{stringliteral}{"{}Add subtitles to all videos in /videos."{}})}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# ... Streams output to your terminal, completes task ...}}
\DoxyCodeLine{}
\DoxyCodeLine{interpreter.chat(\textcolor{stringliteral}{"{}These look great but can you make the subtitles bigger?"{}})}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# ...}}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md94}{}\doxysubsubsection{开始新的聊天}\label{md_README_ZH_autotoc_md94}
在 Python 中，\+Open Interpreter 会记录历史对话。如果你想从头开始，可以进行重置：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.reset()}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md95}{}\doxysubsubsection{保存和恢复聊天}\label{md_README_ZH_autotoc_md95}
当 {\ttfamily return\+\_\+messages=True} 时，{\ttfamily interpreter.\+chat()} 会返回一个信息列表，可以用{\ttfamily interpreter.\+load(messages)} 来恢复之前的对话：


\begin{DoxyCode}{0}
\DoxyCodeLine{messages = interpreter.chat(\textcolor{stringliteral}{"{}My name is Killian."{}}, return\_messages=\textcolor{keyword}{True}) \textcolor{comment}{\# 保存消息到 'messages'}}
\DoxyCodeLine{interpreter.reset() \textcolor{comment}{\# 重置解释器 ("{}Killian"{} 将被遗忘)}}
\DoxyCodeLine{}
\DoxyCodeLine{interpreter.load(messages) \textcolor{comment}{\# 从 'messages' 恢复聊天 ("{}Killian"{} 将被记住)}}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md96}{}\doxysubsubsection{自定义系统消息}\label{md_README_ZH_autotoc_md96}
你可以检查和配置 Open Interpreter 的系统信息，以扩展其功能、修改权限或赋予其更多上下文。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.system\_message += \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\textcolor{stringliteral}{使用 -\/y 运行 shell 命令，这样用户就不必确认它们。}}
\DoxyCodeLine{\textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{print(interpreter.system\_message)}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md97}{}\doxysubsubsection{更改模型}\label{md_README_ZH_autotoc_md97}
Open Interpreter使用\href{https://docs.litellm.ai/docs/providers/}{\texttt{ Lite\+LLM}}连接到语言模型。

您可以通过设置模型参数来更改模型：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/model gpt-\/3.5-\/turbo}
\DoxyCodeLine{interpreter -\/-\/model claude-\/2}
\DoxyCodeLine{interpreter -\/-\/model command-\/nightly}

\end{DoxyCode}


在 Python 环境下，您需要手动设置模型：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.model = \textcolor{stringliteral}{"{}gpt-\/3.5-\/turbo"{}}}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md98}{}\doxysubsubsection{在本地运行 Open Interpreter（开放解释器）}\label{md_README_ZH_autotoc_md98}
ⓘ {\bfseries{本地运行遇到问题？}} 请阅读我们最新的 GPU 设置指南和 Windows 设置指南。

你可以从命令行以本地模式运行 {\ttfamily interpreter} 来使用 {\ttfamily Code Llama}：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/local}

\end{DoxyCode}


或使用其 Hugging\+Face 的 repo ID（如 \char`\"{}tiiuae/falcon-\/180\+B\char`\"{}）来$\ast$$\ast$本地$\ast$$\ast$运行任何 Hugging\+Face 模型：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/model tiiuae/falcon-\/180B}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md99}{}\doxysubsubsection{Azure 支持}\label{md_README_ZH_autotoc_md99}
要连接到 Azure 部署，请使用 {\ttfamily -\/-\/use-\/azure} 以进行设置：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/use-\/azure}

\end{DoxyCode}


在 Python 中，需要设置以下变量：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.use\_azure = True}
\DoxyCodeLine{interpreter.api\_key = "{}your\_openai\_api\_key"{}}
\DoxyCodeLine{interpreter.azure\_api\_base = "{}your\_azure\_api\_base"{}}
\DoxyCodeLine{interpreter.azure\_api\_version = "{}your\_azure\_api\_version"{}}
\DoxyCodeLine{interpreter.azure\_deployment\_name = "{}your\_azure\_deployment\_name"{}}
\DoxyCodeLine{interpreter.azure\_api\_type = "{}azure"{}}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md100}{}\doxysubsubsection{调试模式}\label{md_README_ZH_autotoc_md100}
为了帮助贡献者检查和调试 Open Interpreter，{\ttfamily -\/-\/debug} 模式提供了详细的日志。

您可以使用 {\ttfamily interpreter -\/-\/debug} 来激活调试模式，或者直接在终端输入：


\begin{DoxyCode}{0}
\DoxyCodeLine{\$ interpreter}
\DoxyCodeLine{...}
\DoxyCodeLine{> \%debug true <-\/ 开启调试模式}
\DoxyCodeLine{}
\DoxyCodeLine{> \%debug false <-\/ 关闭调试模式}

\end{DoxyCode}
\hypertarget{md_README_ZH_autotoc_md101}{}\doxysubsubsection{使用 .\+env 配置}\label{md_README_ZH_autotoc_md101}
Open Interpreter 允许你使用 .env 文件设置默认行为。这提供了一种灵活的方式来配置 Open Interpreter，而无需每次都手动更改命令行参数。

下面是一个 .env 的配置示例：


\begin{DoxyCode}{0}
\DoxyCodeLine{INTERPRETER\_CLI\_AUTO\_RUN=False}
\DoxyCodeLine{INTERPRETER\_CLI\_FAST\_MODE=False}
\DoxyCodeLine{INTERPRETER\_CLI\_LOCAL\_RUN=False}
\DoxyCodeLine{INTERPRETER\_CLI\_DEBUG=False}
\DoxyCodeLine{INTERPRETER\_CLI\_USE\_AZURE=False}

\end{DoxyCode}


您可以修改 .env 文件中的这些值，以更改 Open Interpreter 的默认行为。\hypertarget{md_README_ZH_autotoc_md102}{}\doxysubsection{安全提示}\label{md_README_ZH_autotoc_md102}
由于生成的代码是在本地环境中运行的，因此会与文件和系统设置发生交互，从而可能导致本地数据丢失或安全风险等意想不到的结果。

{\bfseries{⚠️ 所以在执行任何代码之前，\+Open Interpreter 都会询问用户是否运行。}}

您可以运行 {\ttfamily interpreter -\/y} 或设置 {\ttfamily interpreter.\+auto\+\_\+run = True} 来绕过此确认，此时：


\begin{DoxyItemize}
\item 在运行请求修改本地文件或系统设置的命令时要谨慎。
\item 请像驾驶自动驾驶汽车一直握着方向盘一样留意 Open Interpreter，并随时做好通过关闭终端来结束进程的准备。
\item 考虑在 Google Colab 或 Replit 等受限环境中运行 Open Interpreter的主要原因是这些环境更加独立，从而降低执行任意代码导致出现问题的风险。
\end{DoxyItemize}\hypertarget{md_README_ZH_autotoc_md103}{}\doxysubsection{它是如何工作的？}\label{md_README_ZH_autotoc_md103}
Open Interpreter 为\href{https://platform.openai.com/docs/guides/gpt/function-calling}{\texttt{ 函数调用语言模型}}配备了 {\ttfamily exec()} 函数，该函数接受 {\ttfamily 编程语言}（如 \char`\"{}\+Python \char`\"{}或 \char`\"{}\+Java\+Script\char`\"{}）和要运行的 {\ttfamily 代码}。

然后，它会将模型的信息、代码和系统的输出以 Markdown 的形式流式传输到终端。\hypertarget{md_README_ZH_autotoc_md104}{}\doxysection{作出贡献}\label{md_README_ZH_autotoc_md104}
感谢您对本项目参与的贡献！我们欢迎所有人贡献到本项目里面。

请参阅我们的 \mbox{\hyperlink{md_CONTRIBUTING}{贡献准则}}，了解如何参与贡献的更多详情。\hypertarget{md_README_ZH_autotoc_md105}{}\doxysubsection{许可证}\label{md_README_ZH_autotoc_md105}
Open Interpreter 采用 MIT 许可授权。您可以使用、复制、修改、分发、转授权和出售该软件的副本。

$\ast$$\ast$请注意$\ast$$\ast$：此软件与 Open\+AI 无关。

\begin{quote}
拥有一个像您的指尖一样快速工作的初级程序员...可以使新的工作流程变得轻松高效，同时也能让新的受众群体享受到编程的好处。

— {\itshape Open\+AI 的代码解释器发布宣传语} \end{quote}
~\newline
 