\doxysection*{● オープン インタープリタ}



\href{https://discord.gg/6p3fD6rBVm}{\texttt{ }} \href{README.md}{\texttt{ }} \href{README_ZH.md}{\texttt{ }}  ~\newline
 ~\newline
 {\bfseries{自然言語で指示するだけでコードを書いて実行までやってくれる。}}~\newline
 ローカルに実装した\+Open\+AI Code Interpreterのオープンソース版。~\newline
 ~\newline
\href{https://openinterpreter.com}{\texttt{ デスクトップアプリケーションへの早期アクセス。}}~\newline
 

~\newline




~\newline



\begin{DoxyCode}{0}
\DoxyCodeLine{pip install open-\/interpreter}

\end{DoxyCode}



\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter}

\end{DoxyCode}


~\newline


$\ast$$\ast$\+Open Interpreter$\ast$$\ast$は、言語モデルに指示し、コード（\+Python、\+Javascript、\+Shellなど）をローカル環境で実行するようにします。インストール後、{\ttfamily \$ interpreter}を実行するとターミナル経由で\+Chat\+GPTのようなインターフェースを介し、\+Open Interpreterとチャットができます。

これにより、自然言語のインターフェースを通して、パソコンの一般的な機能が操作できます。


\begin{DoxyItemize}
\item 写真、動画、\+PDFなどの作成や編集。
\item Chromeブラウザの制御とリサーチ作業。
\item 大規模なデータセットのプロット、クリーニング、分析。
\item 等々
\end{DoxyItemize}

{\bfseries{⚠️ 注意：実行する前にコードを承認するよう求められます。}}

~\newline
\hypertarget{md_README_JA_autotoc_md62}{}\doxysubsection{デモ}\label{md_README_JA_autotoc_md62}
\href{https://github.com/KillianLucas/open-interpreter/assets/63927363/37152071-680d-4423-9af3-64836a6f7b60}{\texttt{ https\+://github.\+com/\+Killian\+Lucas/open-\/interpreter/assets/63927363/37152071-\/680d-\/4423-\/9af3-\/64836a6f7b60}}\hypertarget{md_README_JA_autotoc_md63}{}\doxyparagraph{Google Colabでもインタラクティブなデモを利用できます：}\label{md_README_JA_autotoc_md63}
\href{https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb?usp=sharing}{\texttt{ }}\hypertarget{md_README_JA_autotoc_md64}{}\doxysubsection{クイックスタート}\label{md_README_JA_autotoc_md64}

\begin{DoxyCode}{0}
\DoxyCodeLine{pip install open-\/interpreter}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md65}{}\doxysubsubsection{ターミナル}\label{md_README_JA_autotoc_md65}
インストール後、{\ttfamily interpreter}を実行するだけです：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md66}{}\doxysubsubsection{Python}\label{md_README_JA_autotoc_md66}

\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keyword}{import} interpreter}
\DoxyCodeLine{}
\DoxyCodeLine{interpreter.chat(\textcolor{stringliteral}{"{}AAPLとMETAの株価グラフを描いてください"{}}) \textcolor{comment}{\# 一つのコマンドを実行}}
\DoxyCodeLine{interpreter.chat() \textcolor{comment}{\# インタラクティブなチャットを開始}}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md67}{}\doxysubsection{Chat\+GPTのコードインタープリタとの違い}\label{md_README_JA_autotoc_md67}
GPT-\/4で実装された\+Open\+AIの\href{https://openai.com/blog/chatgpt-plugins\#code-interpreter}{\texttt{ Code Interpreter}} は、実世界のタスクを\+Chat\+GPTで操作できる素晴らしい機会を提供しています。

しかし、\+Open\+AIのサービスはホスティングされていて、クローズドソースで、かなり制限されています：
\begin{DoxyItemize}
\item インターネットに接続できない。
\item \href{https://wfhbrian.com/mastering-chatgpts-code-interpreter-list-of-python-packages/}{\texttt{ プリインストールされているパッケージが限られている}}。
\item 最大アップロードは100\+MBで、120秒という実行時間の制限も。
\item 生成されたファイルやリンクとともに状態がリセットされる。
\end{DoxyItemize}

Open Interpreterは、ローカル環境で操作することで、これらの制限を克服しています。インターネットにフルアクセスでき、時間やファイルサイズの制限を受けず、どんなパッケージやライブラリも利用できます。

Open Interpterは、\+GPT-\/4のコードインタープリタのパワーとローカル開発環境の柔軟性を組み合わせたものです。\hypertarget{md_README_JA_autotoc_md68}{}\doxysubsection{コマンド}\label{md_README_JA_autotoc_md68}
\hypertarget{md_README_JA_autotoc_md69}{}\doxysubsubsection{インタラクティブチャット}\label{md_README_JA_autotoc_md69}
ターミナルでインタラクティブなチャットを開始するには、コマンドラインから{\ttfamily interpreter}を実行します。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter}

\end{DoxyCode}


または、.\+pyファイルから{\ttfamily interpreter.\+chat()}も利用できます。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.chat()}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md70}{}\doxysubsubsection{プログラム的なチャット}\label{md_README_JA_autotoc_md70}
より精確な制御のために、メッセージを直接$<$tt$>$.\+chat(message)に渡すことができます。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.chat(\textcolor{stringliteral}{"{}/videosフォルダにあるすべての動画に字幕を追加する。"{}})}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# ... ターミナルに出力をストリームし、タスクを完了 ...}}
\DoxyCodeLine{}
\DoxyCodeLine{interpreter.chat(\textcolor{stringliteral}{"{}ついでに、字幕を大きくできますか？"{}})}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# ...}}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md71}{}\doxysubsubsection{新しいチャットを開始}\label{md_README_JA_autotoc_md71}
プログラム的チャットで\+Open Interpreterは、会話の履歴を記憶しています。新しくやり直したい場合は、リセットすることができます：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.reset()}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md72}{}\doxysubsubsection{チャットの保存と復元}\label{md_README_JA_autotoc_md72}
{\ttfamily interpreter.\+chat()} は、return\+\_\+messages=True のときにメッセージのリストを返し、{\ttfamily interpreter.\+load(messages)} で会話を再開することができます。


\begin{DoxyCode}{0}
\DoxyCodeLine{messages = interpreter.chat(\textcolor{stringliteral}{"{}私の名前は田中です。"{}}, return\_messages=\textcolor{keyword}{True}) \textcolor{comment}{\# 'messages'にメッセージを保存}}
\DoxyCodeLine{interpreter.reset() \textcolor{comment}{\# インタープリタをリセット（"{}田中"{}は忘れられる）}}
\DoxyCodeLine{}
\DoxyCodeLine{interpreter.load(messages) \textcolor{comment}{\# 'messages'からチャットを再開（"{}田中"{}は記憶される）}}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md73}{}\doxysubsubsection{システムメッセージのカスタマイズ}\label{md_README_JA_autotoc_md73}
Open Interpreterのシステムメッセージを確認し、設定することで、機能を拡張したり、権限を変更したり、またはより多くのコンテキストを与えたりすることができます。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.system\_message += \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\textcolor{stringliteral}{シェルコマンドを「-\/y」フラグ付きで実行し、ユーザーが確認する必要がないようにする。}}
\DoxyCodeLine{\textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{print(interpreter.system\_message)}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md74}{}\doxysubsubsection{モデルの変更}\label{md_README_JA_autotoc_md74}
gpt-\/3.\+5-\/turboの場合は、fastモードを使用する：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/fast}

\end{DoxyCode}


プログラム的チャットでは、モデルを手動で設定する必要がある：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.model = \textcolor{stringliteral}{"{}gpt-\/3.5-\/turbo"{}}}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md75}{}\doxysubsubsection{ローカルのモデルを実行する}\label{md_README_JA_autotoc_md75}
ⓘ {\bfseries{ローカルでの実行に問題ですか？}} 新しいGPUセットアップガイドとWindowsセットアップガイドを参考にしてください。

{\ttfamily Code Llama} を使用するには、コマンドラインからローカルモードで {\ttfamily interpreter} を実行します。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/local}

\end{DoxyCode}


または、\+Hugging Faceモデルをそのレポ\+ID（例えば \char`\"{}tiiuae/falcon-\/180\+B\char`\"{}）を使ってローカルで実行することもできます：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/model tiiuae/falcon-\/180B}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md76}{}\doxysubsubsection{ローカルモデルのパラメータ}\label{md_README_JA_autotoc_md76}
ローカルで実行するモデルの max\+\_\+tokens と context\+\_\+window (トークン単位) を簡単に変更できます。

context\+\_\+windowを小さくすると\+RAMの使用量が減るので、\+GPUが失敗している場合はサイズを短くしてみることをお勧めします。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/max\_tokens 2000 -\/-\/context\_window 16000}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md77}{}\doxysubsubsection{Azureのサポート}\label{md_README_JA_autotoc_md77}
Azureの\+Open\+AI Serviceに接続するには、{\ttfamily -\/-\/use-\/azure}フラグを渡します。


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter -\/-\/use-\/azure}

\end{DoxyCode}


Pythonでは、次の変数を設定します：


\begin{DoxyCode}{0}
\DoxyCodeLine{interpreter.use\_azure = True}
\DoxyCodeLine{interpreter.api\_key = "{}your\_openai\_api\_key"{}}
\DoxyCodeLine{interpreter.azure\_api\_base = "{}your\_azure\_api\_base"{}}
\DoxyCodeLine{interpreter.azure\_api\_version = "{}your\_azure\_api\_version"{}}
\DoxyCodeLine{interpreter.azure\_deployment\_name = "{}your\_azure\_deployment\_name"{}}
\DoxyCodeLine{interpreter.azure\_api\_type = "{}azure"{}}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md78}{}\doxysubsubsection{デバッグモード}\label{md_README_JA_autotoc_md78}
コントリビューターが\+Open Interpreterを調査するのを助けるために、{\ttfamily -\/-\/debug}モードは非常に便利です。

デバッグモードは、フラグ（{\ttfamily interpreter -\/-\/debug}）を使用するか、またはチャットの中から有効にできます：


\begin{DoxyCode}{0}
\DoxyCodeLine{\$ interpreter}
\DoxyCodeLine{...}
\DoxyCodeLine{> \%debug \# <-\/ デバッグモードを有効にする}

\end{DoxyCode}
\hypertarget{md_README_JA_autotoc_md79}{}\doxysubsubsection{.\+envによる設定}\label{md_README_JA_autotoc_md79}
Open Interpreterでは、.\+envファイルを使ってデフォルトの動作を設定することができます。これにより、コマンドライン引数を毎回変更することなく、\+Open Interpreterを柔軟に設定できるようになります。

サンプルの.\+env設定は次のとおりです：


\begin{DoxyCode}{0}
\DoxyCodeLine{INTERPRETER\_CLI\_AUTO\_RUN=False}
\DoxyCodeLine{INTERPRETER\_CLI\_FAST\_MODE=False}
\DoxyCodeLine{INTERPRETER\_CLI\_LOCAL\_RUN=False}
\DoxyCodeLine{INTERPRETER\_CLI\_DEBUG=False}
\DoxyCodeLine{INTERPRETER\_CLI\_USE\_AZURE=False}

\end{DoxyCode}


これらの値を.\+envファイルで変更することで、\+Open Interpreterのデフォルトの動作を変更できます。\hypertarget{md_README_JA_autotoc_md80}{}\doxysubsection{安全に関する注意}\label{md_README_JA_autotoc_md80}
生成されたコードはローカル環境で実行されるため、ファイルやシステム設定と相互作用する可能性があり、データ損失やセキュリティリスクなど予期せぬ結果につながる可能性があります。

{\bfseries{⚠️ Open Interpreterはコードを実行する前にユーザーの確認を求めます。}}

この確認を回避するには、{\ttfamily interpreter -\/y} を実行するか、{\ttfamily interpreter.\+auto\+\_\+run = True} を設定します。その場合：


\begin{DoxyItemize}
\item ファイルやシステム設定を変更するコマンドを要求するときは注意してください。
\item Open Interpreter を自動運転車のように監視し、ターミナルを閉じてプロセスを終了できるように準備しておいてください。
\item Google Colabや\+Replitのような制限された環境で\+Open Interpreterを実行することを検討してください。これらの環境はより隔離されており、任意のコードの実行に関連するリスクを軽減します。
\end{DoxyItemize}\hypertarget{md_README_JA_autotoc_md81}{}\doxysubsection{Open Interpreterはどのように機能するのか？}\label{md_README_JA_autotoc_md81}
Open Interpreterは、\href{https://platform.openai.com/docs/guides/gpt/function-calling}{\texttt{ 関数が呼び出せる言語モデル}}に{\ttfamily exec()}関数を装備し、実行する言語（\char`\"{}python\char`\"{}や\char`\"{}javascript\char`\"{}など）とコードが渡せるようになっています。

そして、モデルからのメッセージ、コード、システムの出力を\+Markdownとしてターミナルにストリーミングします。\hypertarget{md_README_JA_autotoc_md82}{}\doxysection{貢献}\label{md_README_JA_autotoc_md82}
貢献に興味を持っていただき、ありがとうございます！コミュニティからの参加を歓迎しています。

詳しくは、\mbox{\hyperlink{md_CONTRIBUTING}{貢献ガイドライン}}を参照してください。\hypertarget{md_README_JA_autotoc_md83}{}\doxysubsection{ライセンス}\label{md_README_JA_autotoc_md83}
Open Interpreterのライセンスは\+MITライセンスです。本ソフトウェアの使用、複製、変更、配布、サブライセンス、およびコピーの販売を許可します。

{\bfseries{注意}}\+: このソフトウェアは\+Open\+AIとは関係ありません。 \begin{quote}
あなたの指先のスピードで作業するジュニアプログラマーにアクセスすることで、… 新しいワークフローを楽で効率的なものにし、プログラミングの利点を新しいオーディエンスに開放することができます。

— {\itshape Open\+AIのコードインタープリタリリースから} \end{quote}
~\newline
 ~\newline
 ~\newline


{\bfseries{注意}}\+: この翻訳は人工知能によって作成されました。誤りが含まれていることが確実です。 Open Interpreterが世界中を旅するのを助けるため、訂正を含むプルリクエストをしてください！ 